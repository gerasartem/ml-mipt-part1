{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evgenii\\AppData\\Local\\Programs\\Python\\Python36-32\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import gensim\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/eyaler/word2vec-slim/blob/master/GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\")\n",
    "test = pd.read_csv(\"testData.tsv\", sep=\"\\t\")\n",
    "\n",
    "labels = train.sentiment\n",
    "\n",
    "train.drop([\"id\", \"sentiment\"], axis=1, inplace=True)\n",
    "test.drop([\"id\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    regex = \"[^a-zA-Z0-9 ]\"\n",
    "    cleaned_text = re.sub(regex, \"\", text).lower()\n",
    "    \n",
    "    \"\"\"You may add stemming here\"\"\"\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "assert clean_text(\"ASDASDAsdads.,,   asd,.ads012\") == 'asdasdasdads   asdads012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all = pd.concat([train, test], axis=0)\n",
    "\n",
    "all[\"review\"] = all[\"review\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300-SLIM.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def get_vector(words):\n",
    "    words = list(filter(lambda word: word in model.vocab.keys(), words.split()))\n",
    "    \n",
    "    if not words:\n",
    "        return np.zeros(shape=vectors[0].shape[0])\n",
    "    \n",
    "    return ...\n",
    "\n",
    "review_vectors = all.review.apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "_ = tfidf.fit_transform(all.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idfs = list(tfidf.idf_)\n",
    "vocab = tfidf.vocabulary_\n",
    "\n",
    "idfs = {key:idfs[value] for key, value in vocab.items()}\n",
    "\n",
    "def get_vector(words):\n",
    "    words = list(filter(lambda word: word in model.vocab.keys() and word in tfidf.vocabulary_.keys(), words.split()))\n",
    "    \n",
    "    if not words:\n",
    "        return np.zeros(shape=vectors[0].shape[0])\n",
    "    \n",
    "    tf = ...\n",
    "    weights = ...\n",
    "    word_vecs = ...\n",
    "    \n",
    "    return np.multiply(word_vecs, weights.reshape(-1, 1)).sum(axis=0)\n",
    "\n",
    "%%time\n",
    "review_vectors = all.review.apply(get_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del idfs\n",
    "del vocab\n",
    "del tfidf\n",
    "del all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2vs = np.vstack(review_vectors.values)\n",
    "del review_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr = LogisticRegression(C=1e-4)\n",
    "print(cross_val_score(lr, w2vs[:train.shape[0]], labels, scoring=\"roc_auc\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1e-4)\n",
    "lr.fit(w2vs[:train.shape[0]], labels)\n",
    "preds = lr.predict_proba(w2vs[train.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def submit(preds):\n",
    "    submission = pd.read_csv(\"sampleSubmission.csv\")\n",
    "    submission.sentiment = preds\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
