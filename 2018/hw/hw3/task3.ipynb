{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 14pt\">Дедлайн: 20 марта 23:59</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение, ФИВТ, Весна 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall <номер_группы> <фамилия>``, к примеру -- ``ML2018_fall 596 ivanov``\n",
    "- Выполненное дз сохраните в файл ``ML2018_<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2018_ivanov_596_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com`` (или в телеграм-канал)\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, мы не найдем ваше дз, если вы укажете тему письма в неправильном формате.\n",
    "- **PS2**: Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Теоретические задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30% баллов за задание, оценочное время выполнения 30 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что мы решаем задачу бинарной классификации и что у нас есть три алгоритма $b_1(x)$, $b_2(x)$ и $b_3(x)$, каждый из которых ошибается с вероятностью p. Мы строим композицию взвешенным голосованием: алгоритмам присвоены значимости $w_1$, $w_2$ и $w_3$, и для вынесения вердикта суммируются значимости алгоритмов, проголосовавших за каждый из классов:\n",
    "\n",
    "$$a_0 = \\sum_{i=1}^3 w_i [b_i(x)=0]$$\n",
    "$$a_1 = \\sum_{i=1}^3 w_i [b_i(x)=1]$$\n",
    "\n",
    "\n",
    "Объект $x$ относится к классу, для которого такая сумма оказалась максимальной. Например, если первые два алгоритма голосуют за класс $0$, а третий — за класс $1$, то выбирается класс $0$, если $w_1 + w_2 > w_3$, и класс $1$ в противном случае. Какова вероятность ошибки такой композиции этих трех алгоритмов, если:\n",
    "1. $w_1 = 0.2, w_2 = 0.3, w_3 = 0.2$;\n",
    "2. $w_1 = 0.2, w_2 = 0.5, w_3 = 0.2$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу бинарной классификации. Будем считать, что все алгоритмы из базового семейства возвращают ответы из отрезка $[0,1]$, которые можно интерпретировать как вероятности принадлежности объектов классу $1$. В качестве функции потерь возьмем отрицательный логарифм правдоподобия:\n",
    "$$L(y,z) = -(y \\log{z}+(1-y)\\log{(1-z)})$$\n",
    "В формуле $y$ - правильный ответ, $z$ - ответ алгоритма. Выпишите формулы для поиска базовых алгоритмов $b_n$ и коэффициентов $\\gamma_n$ в градиентном бустинге."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 3 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известно, что на $n$-й итерации двухклассового метода AdaBoost\n",
    "был выбран базовый классификатор, допускающий ошибку только на одном объекте $x_j$. Найдите нормированный вес $w_j^{(n+1)}$ при этом объекте на следующей итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 70% баллов за задание, оценочное время выполнения 3 часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация (40%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимо реализовать класс `RandomForest`** (для решения задачи классификации)\n",
    "\n",
    "**Спецификация:**\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    - `num_trees` - количество деревьев в лесе;\n",
    "    - `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    - `max_features` - количество признаков, принимаемое к рассмотрению при разбиении (аналогичный параметр есть в sklearn имплементации). Параметр может принимать значения:\n",
    "        - int - тогда рассматриваем max_features признаков при каждом разбиении;\n",
    "        - float - max_features обозначает процент, int(max_features * n_features) признаков рассматривается при каждом разбиении;\n",
    "        - “sqrt” - max_features=sqrt(n_features);\n",
    "        - “log2” - max_features=log2(n_features);\n",
    "        - None - max_features=n_features;\n",
    "    - `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', по умолчанию - 'gini'); функции с подсчетом энтропийного и критерия Джини можно взять из предыдущего дз;\n",
    "    \n",
    "- класс имеет методы `fit` и `predict`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `RandomForest`, представляющий собой Random Forest, обученный по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(X, y, size):\n",
    "    #Implement random sampling here\n",
    "    sample_X, sample_y = X[:size], y[:size]\n",
    "    return sample_X, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest(sklearn.base.BaseEstimator, sklearn.base.ClassifierMixin):\n",
    "    def __init__(self, num_trees, max_depth, max_features):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        Create trees here, using bagging and RSM.\n",
    "        '''\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Predict the label here using your grown trees.\n",
    "        '''\n",
    "        y_pred = numpy.zeros(X_test.shape[0])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет Wine Data Set (https://archive.ics.uci.edu/ml/datasets/wine). Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=42`. Попробуйте обучить Random Forest на предложенном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, как менялись значения критерия качества `accuracy` при увеличении параметра num_trees. Видны ли следы переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните качество работы вашей реализации RandomForest и реализации из sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модификация Random Forest (15%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Измените свою реализацию `RandomForest` так, чтобы случайное подмножество признаков выбиралось не в каждом сплите, а перед построением всего дерева. Сравните результат работы с обычным RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 with xgboost",
   "language": "python",
   "name": "py3_with_xgboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
