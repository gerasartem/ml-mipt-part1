{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №3 (драфт)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-size: 14pt\">Дедлайн: 20 марта 23:59</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Машинное обучение, ФИВТ, Весна 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оформление дз**: \n",
    "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall <номер_группы> <фамилия>``, к примеру -- ``ML2018_fall 596 ivanov``\n",
    "- Выполненное дз сохраните в файл ``ML2018_<фамилия>_<группа>_task<номер задания>.ipnb``, к примеру -- ``ML2018_ivanov_596_task1.ipnb``\n",
    "\n",
    "**Вопросы**:\n",
    "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
    "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
    "\n",
    "--------\n",
    "- **PS1**: Используются автоматические фильтры, мы не найдем ваше дз, если вы укажете тему письма в неправильном формате.\n",
    "- **PS2**: Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Теоретические задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 20% баллов за задание, оценочное время выполнения 30 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что мы решаем задачу бинарной классификации и что у нас есть три алгоритма $b_1(x)$, $b_2(x)$ и $b_3(x)$, каждый из которых ошибается с вероятностью p. Мы строим композицию взвешенным голосованием: алгоритмам присвоены значимости $w_1$, $w_2$ и $w_3$, и для вынесения вердикта суммируются значимости алгоритмов, проголосовавших за каждый из классов:\n",
    "\n",
    "$$a_0 = \\sum_{i=1}^3 w_i [b_i(x)=0]$$\n",
    "$$a_1 = \\sum_{i=1}^3 w_i [b_i(x)=1]$$\n",
    "\n",
    "\n",
    "Объект $x$ относится к классу, для которого такая сумма оказалась максимальной. Например, если первые два алгоритма голосуют за класс $0$, а третий — за класс $1$, то выбирается класс $0$, если $w_1 + w_2 > w_3$, и класс $1$ в противном случае. Какова вероятность ошибки такой композиции этих трех алгоритмов, если:\n",
    "1. $w_1 = 0.2, w_2 = 0.3, w_3 = 0.2$;\n",
    "2. $w_1 = 0.2, w_2 = 0.5, w_3 = 0.2$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2 (10% баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Известно, что на $n$-й итерации двухклассового метода AdaBoost\n",
    "был выбран базовый классификатор, допускающий ошибку только на одном объекте $x_j$. Найдите нормированный вес $w_j^{(n+1)}$ при этом объекте на следующей итерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 30% баллов за задание, оценочное время выполнения 1 час"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополните код ниже (при желании можно не использовать представленную ниже заготовку и написать полностью свою реализацию AdaBoost):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(pred, Y):\n",
    "    return sum(pred != Y) / float(len(Y))\n",
    "\n",
    "\n",
    "def adaboost_clf(Y_train, X_train, Y_test, X_test, M, clf):\n",
    "    n_train, n_test = len(X_train), len(X_test)\n",
    "    \n",
    "    # Initialize weights\n",
    "    #<YOUR CODE HERE>\n",
    "    \n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    \n",
    "    for i in range(M):\n",
    "        # Fit a classifier with the specific weights\n",
    "        #<YOUR CODE HERE>\n",
    "        \n",
    "        pred_train_i = #<YOUR CODE HERE>\n",
    "        pred_test_i = #<YOUR CODE HERE>\n",
    "        \n",
    "        # Indicator function\n",
    "        miss = [int(x) for x in (pred_train_i != Y_train)]\n",
    "        # Equivalent with 1/-1 to update weights\n",
    "        miss2 = [x if x==1 else -1 for x in miss]\n",
    "        \n",
    "        # Error\n",
    "        err_m = np.dot(w, miss) / sum(w)\n",
    "        \n",
    "        # Alpha\n",
    "        alpha_m = #<YOUR CODE HERE>\n",
    "        \n",
    "        # New weights\n",
    "        w = #<YOUR CODE HERE>\n",
    "        \n",
    "        # Add to prediction\n",
    "        pred_train = [sum(x) for x in zip(pred_train, \n",
    "                                          [x * alpha_m for x in pred_train_i])]\n",
    "        pred_test = [sum(x) for x in zip(pred_test, \n",
    "                                         [x * alpha_m for x in pred_test_i])]\n",
    "    \n",
    "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    \n",
    "    # Return error rate in train and test set\n",
    "    return get_error_rate(pred_train, Y_train), \\\n",
    "           get_error_rate(pred_test, Y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Протестируйте ваш adaboost на примере:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_hastie_10_2()\n",
    "df = pd.DataFrame(x)\n",
    "df['Y'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Деление данных на train и test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "X_train, Y_train = train.ix[:,:-1], train.ix[:,-1]\n",
    "X_test, Y_test = test.ix[:,:-1], test.ix[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите AdaBoost на решающих деревьях (можно использовать DecisionTreeClassifier):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<YOUR CODE HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 50% баллов за задание, оценочное время выполнения 2 часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Реализация (40%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимо реализовать класс `Forest`** (для решения задачи классификации)\n",
    "\n",
    "**Спецификация:**\n",
    "- класс наследуется от `sklearn.BaseEstimator`;\n",
    "- конструктор содержит следующие параметры: \n",
    "    - `num_trees` - количество деревьев в лесе;\n",
    "    - `max_depth` - максимальная глубина дерева (по умолчанию - `numpy.inf`); \n",
    "    - `max_features` - количество признаков, принимаемое к рассмотрению при разбиении (аналогичный параметр есть в sklearn имплементации). Параметр может принимать значения:\n",
    "        - int - тогда рассматриваем max_features признаков при каждом разбиении;\n",
    "        - float - max_features обозначает процент, int(max_features * n_features) признаков рассматривается при каждом разбиении;\n",
    "        - “sqrt” - max_features=sqrt(n_features);\n",
    "        - “log2” - max_features=log2(n_features);\n",
    "        - None - max_features=n_features;\n",
    "    - `criterion` - критерий разбиения (для классификации - 'gini' или 'entropy', для регрессии - 'variance' или 'mad_median'; \n",
    "    по умолчанию - 'gini'); функции с подсчетом энтропийного и критерия Джини можно взять из предыдущего дз;\n",
    "    \n",
    "- класс имеет методы `fit` и `predict`;\n",
    "- метод `fit` принимает матрицу объектов `X` и вектор ответов `y` (объекты `numpy.ndarray`) и возвращает экземпляр класса\n",
    "    `Forest`, представляющий собой Random Forest, обученный по выборке `(X, y)` с учётом заданных в конструкторе параметров; \n",
    "- метод `predict` принимает матрицу объектов и возвращает вектор предсказанных ответов;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(X, y, size):\n",
    "    #Implement random sampling here\n",
    "    sample_X, sample_y = X[:size], y[:size]\n",
    "    return sample_X, sample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forest(sklearn.base.BaseEstimator, sklearn.base.ClassifierMixin):\n",
    "    def __init__(self, num_trees, max_depth, max_features):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        '''\n",
    "        Create trees here, using bagging and RSM.\n",
    "        '''\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        '''\n",
    "        Predict the label here using your grown trees.\n",
    "        '''\n",
    "        y_pred = numpy.zeros(X_test.shape[0])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте Forest на данных из предыдущего дз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `load_digits` загрузите датасет `digits`. Разделите выборку на обучающую и тестовую с помощью метода `train_test_split`, используйте значения параметров `test_size=0.2`, `random_state=42`. Попробуйте обучить Random Forest на предложенном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Покажите, как менялись значения критерия качества `accuracy` при увеличении параметра num_trees. Видны ли следы переобучения?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните качество работы DecisionTree из второго домашнего задания и `Forest` из этого дз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 with xgboost",
   "language": "python",
   "name": "py3_with_xgboost"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
